{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "import torch\n",
    "\n",
    "from torch.autograd import Variable\n",
    "'''\n",
    "这段代码导入了 torch.autograd 模块中的 Variable 类，用于创建可以自动求导的张量。在 PyTorch 中，Variable 已经被整合到张量（Tensor）类中，所以在较新版本的 PyTorch 中，通常不再需要单独导入 Variable 类。您可以直接使用张量进行自动求导操作。\n",
    "'''\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "处理位置信息\n",
    "- 先直接用卷积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LocationLayer(nn.Module):\n",
    "    def __init__(self, attention_n_filters, attention_kernel_size, attention_dim):\n",
    "        super(LocationLayer, self).__init__()\n",
    "        padding = (attention_kernel_size - 1) // 2  # 保持卷积前后形状一致\n",
    "        self.location_conv = nn.Conv1d(2, attention_n_filters,\n",
    "                                       kernel_size=attention_kernel_size,\n",
    "                                       padding=padding, bias=False, stride=1,\n",
    "                                       dilation=1)\n",
    "\n",
    "    def forward(self, attention_weights_cat):\n",
    "        processed_attention = self.location_conv(attention_weights_cat)\n",
    "        processed_attention = torch.transpose(processed_attention, 1, 2)\n",
    "        return processed_attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "attention\n",
    "- 先用linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, attention_rnn_dim, embedding_dim, attention_dim,\n",
    "                 attention_location_n_filters, attention_location_kernel_size):\n",
    "        super(AttentionLayer, self).__init__()\n",
    "\n",
    "        # 注意力权重计算\n",
    "        self.query = nn.Linear(attention_rnn_dim, attention_dim, bias=False)\n",
    "        self.key = nn.Linear(embedding_dim, attention_dim)\n",
    "        self.value = nn.Linear(attention_dim, 1, bias=False)\n",
    "        self.record = nn.Linear(embedding_dim, attention_dim, bias=False)\n",
    "\n",
    "        # 位置信息处理\n",
    "        self.location_conv = nn.Conv1d(2, attention_location_n_filters,\n",
    "                                       kernel_size=attention_location_kernel_size,\n",
    "                                       padding=(attention_location_kernel_size - 1) // 2,\n",
    "                                       bias=False)\n",
    "\n",
    "    def attention_energy(self, query, processed_memory, attention_weights_cat):\n",
    "        processed_query = self.query(query.unsqueeze(1))\n",
    "        processed_attention_weights = self.location_conv(attention_weights_cat)\n",
    "        energies = self.value(torch.tanh(\n",
    "            processed_query + processed_attention_weights + processed_memory))\n",
    "        energies = energies.squeeze(-1)\n",
    "        return energies\n",
    "\n",
    "    def forward(self, attention_hidden_state, memory, processed_memory,\n",
    "                attention_weights_cat):\n",
    "        energy = self.attention_energy(\n",
    "            attention_hidden_state, processed_memory, attention_weights_cat)\n",
    "\n",
    "        attention_weights = F.softmax(energy, dim=1)\n",
    "        attention_context = torch.bmm(attention_weights.unsqueeze(1), memory)\n",
    "        attention_context = attention_context.squeeze(1)\n",
    "        return attention_context, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encoder\n",
    "- conv\n",
    "- bilstm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, encoder_n_convolutions, encoder_embedding_dim, encoder_kernel_size):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        # Convolutional layers 需要传入卷积层数\n",
    "        self.convolutions = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv1d(encoder_embedding_dim, encoder_embedding_dim,\n",
    "                          kernel_size=encoder_kernel_size, stride=1,\n",
    "                          padding=int((encoder_kernel_size - 1) / 2)),\n",
    "                nn.BatchNorm1d(encoder_embedding_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.5)\n",
    "            )\n",
    "            for _ in range(encoder_n_convolutions)\n",
    "        ])\n",
    "\n",
    "        # BiLSTM layer\n",
    "        self.lstm = nn.LSTM(encoder_embedding_dim, int(encoder_embedding_dim / 2), 1,\n",
    "                            batch_first=True, bidirectional=True)\n",
    "\n",
    "    def forward(self, x, input_lengths):\n",
    "        # Convolutional layers\n",
    "        for conv in self.convolutions:\n",
    "            x = conv(x.transpose(1, 2)).transpose(1, 2)\n",
    "\n",
    "        # BiLSTM layer\n",
    "        self.lstm.flatten_parameters()\n",
    "        outputs, _ = self.lstm(x)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def inference(self, x):\n",
    "        # Convolutional layers\n",
    "        for conv in self.convolutions:\n",
    "            x = conv(x.transpose(1, 2)).transpose(1, 2)\n",
    "\n",
    "        # BiLSTM layer\n",
    "        self.lstm.flatten_parameters()\n",
    "        outputs, _ = self.lstm(x)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实体化encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建编码器实例\n",
    "\n",
    "#! 我不知道是多少 参数还没有弄好\n",
    "encoder_n_convolutions, encoder_embedding_dim, encoder_kernel_size = 3,100,100\n",
    "\n",
    "encoder = Encoder(encoder_n_convolutions, encoder_embedding_dim, encoder_kernel_size)\n",
    "\n",
    "# 将输入数据传递给编码器获取编码器的输出\n",
    "encoder_outputs = encoder(input_data, input_lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "decoder\n",
    "- 参数还没有搞好！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, encoder_embedding_dim, decoder_embedding_dim, hidden_dim, output_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # LSTM layer\n",
    "        self.lstm = nn.LSTM(decoder_embedding_dim, hidden_dim, batch_first=True)\n",
    "\n",
    "        # Linear layer to project the LSTM output to the output dimension\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        # Attention layer\n",
    "        self.attention = nn.Linear(encoder_embedding_dim + hidden_dim, 1)\n",
    "\n",
    "    def forward(self, encoder_outputs, decoder_inputs, hidden):\n",
    "        # LSTM layer\n",
    "        decoder_outputs, hidden = self.lstm(decoder_inputs, hidden)\n",
    "\n",
    "        # Attention mechanism\n",
    "        attention_scores = self.attention(torch.cat((encoder_outputs, decoder_outputs), dim=2))\n",
    "        attention_weights = F.softmax(attention_scores, dim=1)\n",
    "        context_vector = torch.bmm(attention_weights.transpose(1, 2), encoder_outputs)\n",
    "\n",
    "        # Linear layer\n",
    "        output = self.fc(torch.cat((decoder_outputs, context_vector), dim=2))\n",
    "\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        # Initialize hidden state and cell state with zeros\n",
    "        return (torch.zeros(1, batch_size, self.hidden_dim),\n",
    "                torch.zeros(1, batch_size, self.hidden_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "还在更新中"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
